{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum k-cut Algorithm\n",
    "\n",
    "### High-level Algorithm Specification:\n",
    "\n",
    "1. Create vertex list and an edges list, e.g.:\n",
    "\n",
    "    ```javascript\n",
    "    vertices = {1: [2,4,5], 2: [3,4,5], 3: [2,4], 4: [1,2,3], 5: [1,2]}\n",
    "    edges = [[1,2], [1,4], [1,5], [2,3], [2,4], [2,5], [3,4]]\n",
    "    ```\n",
    "\n",
    "2. Keep track of the minimum cut so far:\n",
    "\n",
    "    ```javascript\n",
    "    // really this could be the max degree of all vertices, I believe\n",
    "    min_edges_so_far = len(edges)\n",
    "    min_vertex_sets = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "    ```\n",
    "\n",
    "3. *Iterate at least `n^2 log n` times (where n is the original number of vertices)*\n",
    "    \n",
    "    **Intiate:**\n",
    "    \n",
    "    ```javascript\n",
    "    temp_vertex_sets = copy(min_vertex_sets)\n",
    "    temp_vertices = copy(vertices)\n",
    "    temp_edges = copy(edges)\n",
    "    ```\n",
    "\n",
    "    **While num_vertices > k:**\n",
    "\n",
    "    1. Pick an edge at random: the first vertex (`v1`) will absorb the second (`v2`). Add `v2` and `temp_vertex_sets[v2]` to `temp_vertex_sets[v1]` and delete `temp_vertex_sets[v2]`.\n",
    "    2. All vertices adjacent to `v2` are added to `temp_vertices[v1]` unless already present. Remove `v2` from `temp_vertices[v1]`.\n",
    "    3. Replace all instances of `v2` in `temp_edges` with `v1`, unless the other vertex of the edge is itself `v1`. In the latter case, delete the edge (e.g. remove self-loops). **Note:** Parallel edges are allowed; there may be multiple instances of an edge comprised the same vertex pair.\n",
    "\n",
    "    **Finally:** The number of final edges is the number of edges across the final cut in this iteration. If it is less than min_edges_so_far, update `min_edges_so_far = len(temp_edges)` and `min_vertex_sets = temp_vertex_sets`.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Select all measurements and document ids from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import random\n",
    "execfile('utils.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = 'fomc'\n",
    "conn = psycopg2.connect(\"dbname=\" + database + \" user=abarciauskas\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "year = 2006\n",
    "cosine_thresh = 0.25\n",
    "cur.execute(\"SELECT Doc1Id,Doc2Id,CosineSimilarity FROM alignments WHERE Year = '\" + str(year) + \"'\"\n",
    "           \" AND CosineSimilarity >= \" + str(cosine_thresh) + \" ORDER BY random() LIMIT 500\")\n",
    "cosine_sims = cur.fetchall()\n",
    "len(cosine_sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the graph\n",
    "\n",
    "The graph is comprised a list of edges (a vertex tuple) and a dictionary of vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number vertices in complete graph: 607\n",
      "Number edges in complete graph: 500\n"
     ]
    }
   ],
   "source": [
    "edges, vertices = create_graph(cosine_sims)\n",
    "print 'Number vertices in complete graph: ' + str(len(vertices))\n",
    "print 'Number edges in complete graph: ' + str(len(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number vertices fully connected graph: 48\n"
     ]
    }
   ],
   "source": [
    "# need to find disconnected graphs\n",
    "graphs = build_distinct_graphs(vertices)\n",
    "\n",
    "graph_lengths = [len(graph) for graph in graphs]\n",
    "fc_graph = graphs[graph_lengths.index(max(graph_lengths))]\n",
    "print 'Number vertices fully connected graph: ' + str(len(fc_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices in fully connected graph: 48\n",
      "Edges in fully connected graph: 50\n"
     ]
    }
   ],
   "source": [
    "# Remove loner graphs from the most fully connected graph (fc = fully connected)\n",
    "set_fc_graph_vertices = set(fc_graph)\n",
    "loners = set_fc_graph_vertices ^ set(vertices.keys())\n",
    "\n",
    "fc_vertices = deepcopy(vertices)\n",
    "fc_edges = deepcopy(edges)\n",
    "\n",
    "for loner in loners: fc_vertices.pop(loner, None)\n",
    "print 'Vertices in fully connected graph: ' + str(len(fc_vertices))\n",
    "\n",
    "fc_edges = filter(lambda x: not list(x)[0] in loners and not list(x)[1] in loners, fc_edges)    \n",
    "print 'Edges in fully connected graph: ' + str(len(fc_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 & 3: Keep track of minimum so far and run many random iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "execfile('karger_run.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter: 0\n",
      "Total time for 1: 0.00412201881409\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "n = len(fc_vertices)\n",
    "niters = 1\n",
    "\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "min_fc_edges_so_far, min_vertex_sets = karger_run(niters)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "print 'Total time for ' + str(niters) + ': ' + str(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0102134466171\n"
     ]
    }
   ],
   "source": [
    "niters = int(np.ceil(n**2*np.log(n)))\n",
    "\n",
    "total_seconds = niters*total\n",
    "minutes = total_seconds/60\n",
    "hours = minutes/60\n",
    "print hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter: 0\n",
      "Running iter: 50\n",
      "Running iter: 100\n",
      "Running iter: 150\n",
      "Running iter: 200\n",
      "Running iter: 250\n",
      "Running iter: 300\n",
      "Running iter: 350\n",
      "Running iter: 400\n",
      "Running iter: 450\n",
      "Running iter: 500\n",
      "Running iter: 550\n",
      "Running iter: 600\n",
      "Running iter: 650\n",
      "Running iter: 700\n",
      "Running iter: 750\n",
      "Running iter: 800\n",
      "Running iter: 850\n",
      "Running iter: 900\n",
      "Running iter: 950\n",
      "Running iter: 1000\n",
      "Running iter: 1050\n",
      "Running iter: 1100\n",
      "Running iter: 1150\n",
      "Running iter: 1200\n",
      "Running iter: 1250\n",
      "Running iter: 1300\n",
      "Running iter: 1350\n",
      "Running iter: 1400\n",
      "Running iter: 1450\n",
      "Running iter: 1500\n",
      "Running iter: 1550\n",
      "Running iter: 1600\n",
      "Running iter: 1650\n",
      "Running iter: 1700\n",
      "Running iter: 1750\n",
      "Running iter: 1800\n",
      "Running iter: 1850\n",
      "Running iter: 1900\n",
      "Running iter: 1950\n",
      "Running iter: 2000\n",
      "Running iter: 2050\n",
      "Running iter: 2100\n",
      "Running iter: 2150\n",
      "Running iter: 2200\n",
      "Running iter: 2250\n",
      "Running iter: 2300\n",
      "Running iter: 2350\n",
      "Running iter: 2400\n",
      "Running iter: 2450\n",
      "Running iter: 2500\n",
      "Running iter: 2550\n",
      "Running iter: 2600\n",
      "Running iter: 2650\n",
      "Running iter: 2700\n",
      "Running iter: 2750\n",
      "Running iter: 2800\n",
      "Running iter: 2850\n",
      "Running iter: 2900\n",
      "Running iter: 2950\n",
      "Running iter: 3000\n",
      "Running iter: 3050\n",
      "Running iter: 3100\n",
      "Running iter: 3150\n",
      "Running iter: 3200\n",
      "Running iter: 3250\n",
      "Running iter: 3300\n",
      "Running iter: 3350\n",
      "Running iter: 3400\n",
      "Running iter: 3450\n",
      "Running iter: 3500\n",
      "Running iter: 3550\n",
      "Running iter: 3600\n",
      "Running iter: 3650\n",
      "Running iter: 3700\n",
      "Running iter: 3750\n",
      "Running iter: 3800\n",
      "Running iter: 3850\n",
      "Running iter: 3900\n",
      "Running iter: 3950\n",
      "Running iter: 4000\n",
      "Running iter: 4050\n",
      "Running iter: 4100\n",
      "Running iter: 4150\n",
      "Running iter: 4200\n",
      "Running iter: 4250\n",
      "Running iter: 4300\n",
      "Running iter: 4350\n",
      "Running iter: 4400\n",
      "Running iter: 4450\n",
      "Running iter: 4500\n",
      "Running iter: 4550\n",
      "Running iter: 4600\n",
      "Running iter: 4650\n",
      "Running iter: 4700\n",
      "Running iter: 4750\n",
      "Running iter: 4800\n",
      "Running iter: 4850\n",
      "Running iter: 4900\n",
      "Running iter: 4950\n",
      "Running iter: 5000\n",
      "Running iter: 5050\n",
      "Running iter: 5100\n",
      "Running iter: 5150\n",
      "Running iter: 5200\n",
      "Running iter: 5250\n",
      "Running iter: 5300\n",
      "Running iter: 5350\n",
      "Running iter: 5400\n",
      "Running iter: 5450\n",
      "Running iter: 5500\n",
      "Running iter: 5550\n",
      "Running iter: 5600\n",
      "Running iter: 5650\n",
      "Running iter: 5700\n",
      "Running iter: 5750\n",
      "Running iter: 5800\n",
      "Running iter: 5850\n",
      "Running iter: 5900\n",
      "Running iter: 5950\n",
      "Running iter: 6000\n",
      "Running iter: 6050\n",
      "Running iter: 6100\n",
      "Running iter: 6150\n",
      "Running iter: 6200\n",
      "Running iter: 6250\n",
      "Running iter: 6300\n",
      "Running iter: 6350\n",
      "Running iter: 6400\n",
      "Running iter: 6450\n",
      "Running iter: 6500\n",
      "Running iter: 6550\n",
      "Running iter: 6600\n",
      "Running iter: 6650\n",
      "Running iter: 6700\n",
      "Running iter: 6750\n",
      "Running iter: 6800\n",
      "Running iter: 6850\n",
      "Running iter: 6900\n",
      "Running iter: 6950\n",
      "Running iter: 7000\n",
      "Running iter: 7050\n",
      "Running iter: 7100\n",
      "Running iter: 7150\n",
      "Running iter: 7200\n",
      "Running iter: 7250\n",
      "Running iter: 7300\n",
      "Running iter: 7350\n",
      "Running iter: 7400\n",
      "Running iter: 7450\n",
      "Running iter: 7500\n",
      "Running iter: 7550\n",
      "Running iter: 7600\n",
      "Running iter: 7650\n",
      "Running iter: 7700\n",
      "Running iter: 7750\n",
      "Running iter: 7800\n",
      "Running iter: 7850\n",
      "Running iter: 7900\n",
      "Running iter: 7950\n",
      "Running iter: 8000\n",
      "Running iter: 8050\n",
      "Running iter: 8100\n",
      "Running iter: 8150\n",
      "Running iter: 8200\n",
      "Running iter: 8250\n",
      "Running iter: 8300\n",
      "Running iter: 8350\n",
      "Running iter: 8400\n",
      "Running iter: 8450\n",
      "Running iter: 8500\n",
      "Running iter: 8550\n",
      "Running iter: 8600\n",
      "Running iter: 8650\n",
      "Running iter: 8700\n",
      "Running iter: 8750\n",
      "Running iter: 8800\n",
      "Running iter: 8850\n",
      "Running iter: 8900\n",
      "Total time for 8920: 25.2881991863\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "min_edges_so_far, min_vertex_sets = karger_run(niters)\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print 'Total time for ' + str(niters) + ': ' + str(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num crossing edges: 9\n",
      "Total time for 8920 iterations: 0.00702449977398 hours\n",
      "Number of actual clusters: 2\n",
      "Super node of size: 25\n",
      "Super node of size: 9\n"
     ]
    }
   ],
   "source": [
    "print 'Num crossing edges: ' + str(min_edges_so_far)\n",
    "total = t1-t0\n",
    "print 'Total time for ' + str(niters) + ' iterations: ' + str(total/60/60) + ' hours'\n",
    "super_nodes = min_vertex_sets.keys()\n",
    "super_nodes = filter(lambda x: len(min_vertex_sets[x]) >= 4, super_nodes)\n",
    "nclusters = len(super_nodes)\n",
    "print 'Number of actual clusters: ' + str(nclusters)\n",
    "for node in super_nodes: print 'Super node of size: ' + str(len(min_vertex_sets[node]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\_\\_\\_\\_\n",
      "\n",
      "**Cluster 1**\n",
      "\n",
      "*Representative:*\n",
      "> In the Committee� s discussion of monetary policy for the intermeeting period, nearly all members favored keeping the target federal funds rate at 5-1/4 percent at this meeting.\n",
      "\n",
      "| Top Terms   |   Relative Frequency |\n",
      "|:------------|---------------------:|\n",
      "| posit       |                    1 |\n",
      "| mount       |                    1 |\n",
      "| compromis   |                    1 |\n",
      "| strengthen  |                    1 |\n",
      "| vari        |                    1 |\n",
      "| declinar    |                    1 |\n",
      "| gener       |                    1 |\n",
      "| commit      |                    1 |\n",
      "| pace        |                    1 |\n",
      "| runoff      |                    1 |\n",
      "| forecast    |                    1 |\n",
      "| must        |                    1 |\n",
      "| executiu    |                    1 |\n",
      "| suppli      |                    1 |\n",
      "| volatil     |                    1 |\n",
      "| baby-boom   |                    1 |\n",
      "| two         |                    1 |\n",
      "| advantag    |                    1 |\n",
      "| latest      |                    1 |\n",
      "| non-energi  |                    1 |\n",
      "\n",
      "\n",
      "\n",
      "\\_\\_\\_\\_\n",
      "\n",
      "**Cluster 2**\n",
      "\n",
      "*Representative:*\n",
      "> The Manager shall clear with the Committee (or with the Subcommittee, if the Subcommittee believes that consultation with the full Committee is not feasible in the time available, or with the Chairman, if the Chairman believes that consultation with the Subcommittee is not feasible in the time available): A. Any operation that would result in a change in the Systems overall open position in foreign currencies exceeding $1.5 billion since the most recent regular meeting of the Committee.\n",
      "\n",
      "| Top Terms             |   Relative Frequency |\n",
      "|:----------------------|---------------------:|\n",
      "| question              |                    1 |\n",
      "| shortli               |                    1 |\n",
      "| shift                 |                    1 |\n",
      "| durat                 |                    1 |\n",
      "| dollar                |                    1 |\n",
      "| delinqu               |                    1 |\n",
      "| with                  |                    1 |\n",
      "| pla                   |                    1 |\n",
      "| matter                |                    1 |\n",
      "| size                  |                    1 |\n",
      "| lessen                |                    1 |\n",
      "| financ                |                    1 |\n",
      "| identifi              |                    1 |\n",
      "| slip                  |                    1 |\n",
      "| regard                |                    1 |\n",
      "| cite                  |                    1 |\n",
      "| pleasur               |                    1 |\n",
      "| ago                   |                    1 |\n",
      "| neg                   |                    1 |\n",
      "| two-and-one-half-year |                    1 |\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execfile('utils.py')\n",
    "\n",
    "# find the relative frequency for each super node\n",
    "cur.execute(\"SELECT TermVector FROM corpii WHERE Year = '\" + str(year) + \"'\")\n",
    "terms = cur.fetchall()[0][0]\n",
    "nterms = len(terms)\n",
    "\n",
    "cluster_frequencies, overall_frequencies = sum_term_frequencies(cur, nterms, nclusters, super_nodes, min_vertex_sets)\n",
    "cluster_frequencies_normalized = normalize_term_frequencies(nterms, cluster_frequencies, overall_frequencies)\n",
    "print_clusters(cur, super_nodes, cluster_frequencies_normalized, 20, terms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
