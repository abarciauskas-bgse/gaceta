{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum k-cut Algorithm\n",
    "\n",
    "### High-level Algorithm Specification:\n",
    "\n",
    "1. Create vertex list and an edges list, e.g.:\n",
    "\n",
    "    ```javascript\n",
    "    vertices = {1: [2,4,5], 2: [3,4,5], 3: [2,4], 4: [1,2,3], 5: [1,2]}\n",
    "    edges = [[1,2], [1,4], [1,5], [2,3], [2,4], [2,5], [3,4]]\n",
    "    ```\n",
    "\n",
    "2. Keep track of the minimum cut so far:\n",
    "\n",
    "    ```javascript\n",
    "    // really this could be the max degree of all vertices, I believe\n",
    "    min_edges_so_far = len(edges)\n",
    "    min_vertex_sets = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "    ```\n",
    "\n",
    "3. *Iterate at least `n^2 log n` times (where n is the original number of vertices)*\n",
    "    \n",
    "    **Intiate:**\n",
    "    \n",
    "    ```javascript\n",
    "    temp_vertex_sets = copy(min_vertex_sets)\n",
    "    temp_vertices = copy(vertices)\n",
    "    temp_edges = copy(edges)\n",
    "    ```\n",
    "\n",
    "    **While num_vertices > k:**\n",
    "\n",
    "    1. Pick an edge at random: the first vertex (`v1`) will absorb the second (`v2`). Add `v2` and `temp_vertex_sets[v2]` to `temp_vertex_sets[v1]` and delete `temp_vertex_sets[v2]`.\n",
    "    2. All vertices adjacent to `v2` are added to `temp_vertices[v1]` unless already present. Remove `v2` from `temp_vertices[v1]`.\n",
    "    3. Replace all instances of `v2` in `temp_edges` with `v1`, unless the other vertex of the edge is itself `v1`. In the latter case, delete the edge (e.g. remove self-loops). **Note:** Parallel edges are allowed; there may be multiple instances of an edge comprised the same vertex pair.\n",
    "\n",
    "    **Finally:** The number of final edges is the number of edges across the final cut in this iteration. If it is less than min_edges_so_far, update `min_edges_so_far = len(temp_edges)` and `min_vertex_sets = temp_vertex_sets`.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Select all measurements and document ids from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import random\n",
    "execfile('utils.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = 'fomc'\n",
    "conn = psycopg2.connect(\"dbname=\" + database + \" user=abarciauskas\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "year = '20031'\n",
    "cosine_thresh = 0.25\n",
    "cur.execute(\"SELECT Doc1Id,Doc2Id,CosineSimilarity FROM alignments WHERE Year = '\" + str(year) + \"'\"\n",
    "           \" AND CosineSimilarity >= \" + str(cosine_thresh) + \" ORDER BY random() LIMIT 500\")\n",
    "cosine_sims = cur.fetchall()\n",
    "len(cosine_sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the graph\n",
    "\n",
    "The graph is comprised a list of edges (a vertex tuple) and a dictionary of vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number vertices in complete graph: 169\n",
      "Number edges in complete graph: 171\n"
     ]
    }
   ],
   "source": [
    "edges, vertices = create_graph(cosine_sims)\n",
    "print 'Number vertices in complete graph: ' + str(len(vertices))\n",
    "print 'Number edges in complete graph: ' + str(len(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number vertices fully connected graph: 34\n"
     ]
    }
   ],
   "source": [
    "# need to find disconnected graphs\n",
    "graphs = build_distinct_graphs(vertices)\n",
    "\n",
    "graph_lengths = [len(graph) for graph in graphs]\n",
    "fc_graph = graphs[graph_lengths.index(max(graph_lengths))]\n",
    "print 'Number vertices fully connected graph: ' + str(len(fc_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices in fully connected graph: 34\n",
      "Edges in fully connected graph: 48\n"
     ]
    }
   ],
   "source": [
    "# Remove loner graphs from the most fully connected graph (fc = fully connected)\n",
    "set_fc_graph_vertices = set(fc_graph)\n",
    "loners = set_fc_graph_vertices ^ set(vertices.keys())\n",
    "\n",
    "fc_vertices = deepcopy(vertices)\n",
    "fc_edges = deepcopy(edges)\n",
    "\n",
    "for loner in loners: fc_vertices.pop(loner, None)\n",
    "print 'Vertices in fully connected graph: ' + str(len(fc_vertices))\n",
    "\n",
    "fc_edges = filter(lambda x: not list(x)[0] in loners and not list(x)[1] in loners, fc_edges)    \n",
    "print 'Edges in fully connected graph: ' + str(len(fc_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 & 3: Keep track of minimum so far and run many random iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "execfile('karger_run.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter: 0\n",
      "Total time for 1: 0.00417494773865\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "n = len(fc_vertices)\n",
    "niters = 1\n",
    "\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "min_fc_edges_so_far, min_vertex_sets = karger_run(niters)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "print 'Total time for ' + str(niters) + ': ' + str(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00472812831402\n"
     ]
    }
   ],
   "source": [
    "niters = int(np.ceil(n**2*np.log(n)))\n",
    "\n",
    "total_seconds = niters*total\n",
    "minutes = total_seconds/60\n",
    "hours = minutes/60\n",
    "print hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter: 0\n",
      "Running iter: 50\n",
      "Running iter: 100\n",
      "Running iter: 150\n",
      "Running iter: 200\n",
      "Running iter: 250\n",
      "Running iter: 300\n",
      "Running iter: 350\n",
      "Running iter: 400\n",
      "Running iter: 450\n",
      "Running iter: 500\n",
      "Running iter: 550\n",
      "Running iter: 600\n",
      "Running iter: 650\n",
      "Running iter: 700\n",
      "Running iter: 750\n",
      "Running iter: 800\n",
      "Running iter: 850\n",
      "Running iter: 900\n",
      "Running iter: 950\n",
      "Running iter: 1000\n",
      "Running iter: 1050\n",
      "Running iter: 1100\n",
      "Running iter: 1150\n",
      "Running iter: 1200\n",
      "Running iter: 1250\n",
      "Running iter: 1300\n",
      "Running iter: 1350\n",
      "Running iter: 1400\n",
      "Running iter: 1450\n",
      "Running iter: 1500\n",
      "Running iter: 1550\n",
      "Running iter: 1600\n",
      "Running iter: 1650\n",
      "Running iter: 1700\n",
      "Running iter: 1750\n",
      "Running iter: 1800\n",
      "Running iter: 1850\n",
      "Running iter: 1900\n",
      "Running iter: 1950\n",
      "Running iter: 2000\n",
      "Running iter: 2050\n",
      "Running iter: 2100\n",
      "Running iter: 2150\n",
      "Running iter: 2200\n",
      "Running iter: 2250\n",
      "Running iter: 2300\n",
      "Running iter: 2350\n",
      "Running iter: 2400\n",
      "Running iter: 2450\n",
      "Running iter: 2500\n",
      "Running iter: 2550\n",
      "Running iter: 2600\n",
      "Running iter: 2650\n",
      "Running iter: 2700\n",
      "Running iter: 2750\n",
      "Running iter: 2800\n",
      "Running iter: 2850\n",
      "Running iter: 2900\n",
      "Running iter: 2950\n",
      "Running iter: 3000\n",
      "Running iter: 3050\n",
      "Running iter: 3100\n",
      "Running iter: 3150\n",
      "Running iter: 3200\n",
      "Running iter: 3250\n",
      "Running iter: 3300\n",
      "Running iter: 3350\n",
      "Running iter: 3400\n",
      "Running iter: 3450\n",
      "Running iter: 3500\n",
      "Running iter: 3550\n",
      "Running iter: 3600\n",
      "Running iter: 3650\n",
      "Running iter: 3700\n",
      "Running iter: 3750\n",
      "Running iter: 3800\n",
      "Running iter: 3850\n",
      "Running iter: 3900\n",
      "Running iter: 3950\n",
      "Running iter: 4000\n",
      "Running iter: 4050\n",
      "Total time for 4077: 13.9757931232\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "min_edges_so_far, min_vertex_sets = karger_run(niters)\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print 'Total time for ' + str(niters) + ': ' + str(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num crossing edges: 9\n",
      "Total time for 4077 iterations: 0.00388216475646 hours\n",
      "Number of actual clusters: 3\n",
      "Super node of size: 3\n",
      "Super node of size: 11\n",
      "Super node of size: 9\n"
     ]
    }
   ],
   "source": [
    "print 'Num crossing edges: ' + str(min_edges_so_far)\n",
    "total = t1-t0\n",
    "print 'Total time for ' + str(niters) + ' iterations: ' + str(total/60/60) + ' hours'\n",
    "super_nodes = min_vertex_sets.keys()\n",
    "super_nodes = filter(lambda x: len(min_vertex_sets[x]) >= 3, super_nodes)\n",
    "nclusters = len(super_nodes)\n",
    "print 'Number of actual clusters: ' + str(nclusters)\n",
    "for node in super_nodes: print 'Super node of size: ' + str(len(min_vertex_sets[node]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\_\\_\\_\\_\n",
      "\n",
      "**Cluster 1**\n",
      "\n",
      "*Representative:*\n",
      "> \" The Federal Open Market Committee seeks monetary and financial conditions that will foster price stability and promote sustainable growth in output. To further its long-run objectives, the Committee in the immediate future seeks conditions in reserve markets consistent with maintaining the federal funds rate at an average of around 1 percent.\" The vote encompassed the following statements concerning the risks to the Committees outlook for economic growth and inflation.\n",
      "\n",
      "| Top Terms   |   Relative Frequency |\n",
      "|:------------|---------------------:|\n",
      "| upgrad      |                    1 |\n",
      "| reportedli  |                    1 |\n",
      "| concern     |                    1 |\n",
      "| thought     |                    1 |\n",
      "| delet       |                    1 |\n",
      "| down        |                    1 |\n",
      "| longer      |                    1 |\n",
      "| privat      |                    1 |\n",
      "| attent      |                    1 |\n",
      "| consum      |                    1 |\n",
      "| gain        |                    1 |\n",
      "| sentiment   |                    1 |\n",
      "| short-run   |                    1 |\n",
      "| otherwis    |                    1 |\n",
      "| notabl      |                    1 |\n",
      "| next        |                    1 |\n",
      "| howev       |                    1 |\n",
      "| restrain    |                    1 |\n",
      "| approach    |                    1 |\n",
      "| even        |                    1 |\n",
      "\n",
      "\n",
      "\n",
      "\\_\\_\\_\\_\n",
      "\n",
      "**Cluster 2**\n",
      "\n",
      "*Representative:*\n",
      "> Over the twelve months ending in October, core consumer prices rose only slightly and noticeably less than in the previous twelve-month period.\n",
      "\n",
      "| Top Terms   |   Relative Frequency |\n",
      "|:------------|---------------------:|\n",
      "| call        |                    1 |\n",
      "| understand  |                    1 |\n",
      "| gather      |                    1 |\n",
      "| reduc       |                    1 |\n",
      "| order       |                    1 |\n",
      "| boost       |                    1 |\n",
      "| wage        |                    1 |\n",
      "| practic     |                    1 |\n",
      "| period      |                    1 |\n",
      "| rel         |                    1 |\n",
      "| close       |                    1 |\n",
      "| dure        |                    1 |\n",
      "| weight      |                    1 |\n",
      "| maintain    |                    1 |\n",
      "| uncertainti |                    1 |\n",
      "| larger      |                    1 |\n",
      "| state       |                    1 |\n",
      "| expenditur  |                    1 |\n",
      "| transact    |                    1 |\n",
      "| risen       |                    1 |\n",
      "\n",
      "\n",
      "\n",
      "\\_\\_\\_\\_\n",
      "\n",
      "**Cluster 3**\n",
      "\n",
      "*Representative:*\n",
      "> In reaching this decision, the Committee members generally perceived the upside and downside risks to the attainment of sustainable growth for the next few quarters to be roughly equal; however, they viewed the probability, though minor, of an unwelcome fall in inflation as exceeding that of a rise in inflation from its already low level.\n",
      "\n",
      "| Top Terms   |   Relative Frequency |\n",
      "|:------------|---------------------:|\n",
      "| nonbusi     |                    1 |\n",
      "| togeth      |                    1 |\n",
      "| cash        |                    1 |\n",
      "| escal       |                    1 |\n",
      "| restock     |                    1 |\n",
      "| alreadi     |                    1 |\n",
      "| consensu    |                    1 |\n",
      "| had         |                    1 |\n",
      "| rebound     |                    1 |\n",
      "| deficit     |                    1 |\n",
      "| midyear     |                    1 |\n",
      "| accord      |                    1 |\n",
      "| consumpt    |                    1 |\n",
      "| lower-ti    |                    1 |\n",
      "| post        |                    1 |\n",
      "| concerndr   |                    1 |\n",
      "| recent      |                    1 |\n",
      "| limit       |                    1 |\n",
      "| shown       |                    1 |\n",
      "| price       |                    1 |\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the relative frequency for each super node\n",
    "execfile('utils.py')\n",
    "cur.execute(\"SELECT TermVector FROM corpii WHERE Year = '\" + str(year) + \"'\")\n",
    "terms = cur.fetchall()[0][0]\n",
    "nterms = len(terms)\n",
    "\n",
    "cluster_frequencies, overall_frequencies = sum_term_frequencies(cur, nterms, nclusters, super_nodes, min_vertex_sets)\n",
    "cluster_frequencies_normalized = normalize_term_frequencies(nterms, cluster_frequencies, overall_frequencies)\n",
    "print_clusters(cur, super_nodes, cluster_frequencies_normalized, 20, terms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
