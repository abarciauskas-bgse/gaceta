{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum k-cut Algorithm\n",
    "\n",
    "### High-level Algorithm Specification:\n",
    "\n",
    "1. Create vertex list and an edges list, e.g.:\n",
    "\n",
    "    ```javascript\n",
    "    vertices = {1: [2,4,5], 2: [3,4,5], 3: [2,4], 4: [1,2,3], 5: [1,2]}\n",
    "    edges = [[1,2], [1,4], [1,5], [2,3], [2,4], [2,5], [3,4]]\n",
    "    ```\n",
    "\n",
    "2. Keep track of the minimum cut so far:\n",
    "\n",
    "    ```javascript\n",
    "    // really this could be the max degree of all vertices, I believe\n",
    "    min_edges_so_far = len(edges)\n",
    "    min_vertex_sets = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "    ```\n",
    "\n",
    "3. *Iterate at least `n^2 log n` times (where n is the original number of vertices)*\n",
    "    \n",
    "    **Intiate:**\n",
    "    \n",
    "    ```javascript\n",
    "    temp_vertex_sets = copy(min_vertex_sets)\n",
    "    temp_vertices = copy(vertices)\n",
    "    temp_edges = copy(edges)\n",
    "    ```\n",
    "\n",
    "    **While num_vertices > k:**\n",
    "\n",
    "    1. Pick an edge at random: the first vertex (`v1`) will absorb the second (`v2`). Add `v2` and `temp_vertex_sets[v2]` to `temp_vertex_sets[v1]` and delete `temp_vertex_sets[v2]`.\n",
    "    2. All vertices adjacent to `v2` are added to `temp_vertices[v1]` unless already present. Remove `v2` from `temp_vertices[v1]`.\n",
    "    3. Replace all instances of `v2` in `temp_edges` with `v1`, unless the other vertex of the edge is itself `v1`. In the latter case, delete the edge (e.g. remove self-loops). **Note:** Parallel edges are allowed; there may be multiple instances of an edge comprised the same vertex pair.\n",
    "\n",
    "    **Finally:** The number of final edges is the number of edges across the final cut in this iteration. If it is less than min_edges_so_far, update `min_edges_so_far = len(temp_edges)` and `min_vertex_sets = temp_vertex_sets`.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Select all measurements and document ids from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "database = 'fomc'\n",
    "conn = psycopg2.connect(\"dbname=\" + database + \" user=abarciauskas\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "year = 2006\n",
    "cosine_thresh = 0.25\n",
    "limit = 1000\n",
    "cur.execute(\"SELECT Doc1Id,Doc2Id,CosineSimilarity FROM alignments WHERE Year = '\" + str(year) + \"'\"\n",
    "           \" AND CosineSimilarity >= \" + str(cosine_thresh) + \" ORDER BY random() LIMIT \" + str(limit))\n",
    "cosine_sims = cur.fetchall()\n",
    "len(cosine_sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the graph\n",
    "\n",
    "The graph is comprised a list of edges (a vertex tuple) and a dictionary of vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "def create_graph(alignments):\n",
    "    edges = [tuple([x[0],x[1]]) for x in alignments]\n",
    "    vertices = {}\n",
    "    for edge in edges:\n",
    "        v1 = edge[0]\n",
    "        v2 = edge[1]\n",
    "        if v1 in vertices.keys():\n",
    "            vertices[v1].add(v2)\n",
    "        else:\n",
    "            vertices[v1] = {v2}\n",
    "        if v2 in vertices.keys():\n",
    "            vertices[v2].add(v1)\n",
    "        else:\n",
    "            vertices[v2] = {v1}\n",
    "    return [edges, vertices]\n",
    "\n",
    "edges, vertices = create_graph(cosine_sims)\n",
    "print len(vertices)\n",
    "print len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number vertices fully connected graph: 524\n"
     ]
    }
   ],
   "source": [
    "# need to find disconnected graphs\n",
    "graphs = []\n",
    "unvisited = set(vertices.keys())\n",
    "\n",
    "#Detect distinct graphs\n",
    "while len(unvisited) > 0:\n",
    "    # for every vertex, find all of its connected components and recurse on those vertices\n",
    "    visited = []\n",
    "    current_vertex = unvisited.pop()\n",
    "    visited.append(current_vertex)\n",
    "    stack_to_visit = list(vertices[current_vertex])\n",
    "    while len(stack_to_visit) > 0:\n",
    "        current_vertex = stack_to_visit.pop()\n",
    "        current_adj_vtcs = vertices[current_vertex]\n",
    "        if current_vertex not in visited: visited.append(current_vertex)\n",
    "        if current_vertex in unvisited: unvisited.remove(current_vertex)        \n",
    "        for v in current_adj_vtcs:\n",
    "            if v not in visited:\n",
    "                stack_to_visit.insert(0, v)\n",
    "    graphs.append(visited)\n",
    "\n",
    "# print len(unvisited)\n",
    "# print len(visited)\n",
    "# print len(graphs)\n",
    "# print ''\n",
    "\n",
    "graph_lengths = [len(graph) for graph in graphs]\n",
    "fc_graph = graphs[graph_lengths.index(max(graph_lengths))]\n",
    "print 'Number vertices fully connected graph: ' + str(len(fc_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n",
      "524\n",
      "1000\n",
      "738\n"
     ]
    }
   ],
   "source": [
    "# Remove loner graphs\n",
    "# fc = fully connected\n",
    "set_fc_graph_vertices = set(fc_graph)\n",
    "loners = set_fc_graph_vertices ^ set(vertices.keys())\n",
    "\n",
    "fc_vertices = deepcopy(vertices)\n",
    "fc_edges = deepcopy(edges)\n",
    "\n",
    "print(len(fc_vertices))\n",
    "for loner in loners:\n",
    "    fc_vertices.pop(loner, None)\n",
    "print(len(fc_vertices))\n",
    "\n",
    "print(len(fc_edges))\n",
    "fc_edges = filter(lambda x: not list(x)[0] in loners and not list(x)[1] in loners, fc_edges)    \n",
    "print(len(fc_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Keep track of minimum so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Random iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def run(niters):\n",
    "    min_fc_edges_so_far = len(fc_edges)\n",
    "    min_vertex_sets = {key: set() for key in fc_vertices.keys()}\n",
    "    for iteridx in range(niters):\n",
    "        if iteridx % 50 == 0: print 'Running iter: ' + str(iteridx)        \n",
    "        temp_vertex_sets = {key: set() for key in fc_vertices.keys()}\n",
    "        temp_fc_vertices = deepcopy(fc_vertices)\n",
    "        temp_fc_edges = fc_edges[:]        \n",
    "        while len(temp_fc_vertices) > k:\n",
    "            # pick an edge at random and delete it\n",
    "            rand_idx = int(random.random()*len(temp_fc_edges))\n",
    "            random_edge = temp_fc_edges.pop(rand_idx)\n",
    "            # Add v2 and temp_vertex_sets[v2] to temp_vertex_sets[v1] and delete temp_vertex_sets[v2]\n",
    "            v1 = list(random_edge)[0]\n",
    "            v2 = list(random_edge)[1]\n",
    "            temp_vertex_sets[v1] = temp_vertex_sets[v1].union(temp_vertex_sets[v2])\n",
    "            temp_vertex_sets[v1].add(v2)\n",
    "            temp_vertex_sets.pop(v2, None)\n",
    "\n",
    "            # All fc_vertices adjacent to v2 are added to temp_fc_vertices[v1] unless already present.\n",
    "            # Remove v2 from temp_fc_vertices[v1].\n",
    "            adj_v2 = temp_fc_vertices[v2]\n",
    "            temp_fc_vertices[v1] = temp_fc_vertices[v1].union(adj_v2)\n",
    "            temp_fc_vertices[v1].remove(v2)\n",
    "            temp_fc_vertices.pop(v2, None)\n",
    "\n",
    "            # Replace all instances of v2 in temp_fc_edges with v1, unless the other vertex of the edge is itself v1.\n",
    "            # In the latter case, delete the edge (e.g. remove self-loops).\n",
    "            # Note: Parallel fc_edges are allowed; there may be multiple instances of an edge comprised the same vertex pair.\n",
    "            remove_fc_edges = []\n",
    "            for i,cur_edge in enumerate(temp_fc_edges):\n",
    "                if len(cur_edge) > 1:\n",
    "                    cur_edge_v1 = list(cur_edge)[0]\n",
    "                    cur_edge_v2 = list(cur_edge)[1]\n",
    "                    if (cur_edge == random_edge):\n",
    "                        remove_fc_edges.append(i)\n",
    "                    elif cur_edge_v1 == v2:\n",
    "                        temp_fc_edges[i] = {v1, cur_edge_v2}\n",
    "                        # remove this edge from temp_fc_vertices\n",
    "                        # it may have already been removed because we keep parallel fc_edges around\n",
    "                        if v2 in temp_fc_vertices[cur_edge_v2]: temp_fc_vertices[cur_edge_v2].remove(v2)\n",
    "                    elif cur_edge_v2 == v2:\n",
    "                        temp_fc_edges[i] = {cur_edge_v1, v1}\n",
    "                        # it may have already been removed because we keep parallel fc_edges around\n",
    "                        if v2 in temp_fc_vertices[cur_edge_v1]: temp_fc_vertices[cur_edge_v1].remove(v2)\n",
    "            # work around for delete\n",
    "            temp_fc_edges = [set(i) for j, i in enumerate(temp_fc_edges) if j not in remove_fc_edges]\n",
    "            #Finally: The number of final fc_edges is the number of fc_edges across the final cut in this iteration.\n",
    "            #If it is less than min_fc_edges_so_far, update min_fc_edges_so_far = len(temp_fc_edges) and min_vertex_sets = temp_vertex_sets.\n",
    "            if len(temp_fc_edges) < min_fc_edges_so_far:\n",
    "                min_fc_edges_so_far = len(temp_fc_edges)\n",
    "                min_vertex_sets = temp_vertex_sets\n",
    "    return min_fc_edges_so_far, min_vertex_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter: 0\n",
      "Total time for 1: 0.288903951645\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "n = len(fc_vertices)\n",
    "niters = 1\n",
    "\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "min_fc_edges_so_far, min_vertex_sets = run(niters)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "print 'Total time for ' + str(niters) + ': ' + str(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.802510976791\n"
     ]
    }
   ],
   "source": [
    "niters = n**2#int(np.ceil(n**2*np.log(n)))\n",
    "niters = 10000\n",
    "total_seconds = niters*total\n",
    "minutes = total_seconds/60\n",
    "hours = minutes/60\n",
    "print hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for 10000: 2612.97274208\n"
     ]
    }
   ],
   "source": [
    "niters = 10000\n",
    "t0 = time.time()\n",
    "min_edges_so_far, min_vertex_sets = run(niters)\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print 'Total time for ' + str(niters) + ': ' + str(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num crossing edges: 9\n",
      "Total time for 10000 iterations: 0.725825761689\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print 'Num crossing edges: ' + str(min_edges_so_far)\n",
    "total = t1-t0\n",
    "print 'Total time for ' + str(niters) + ' iterations: ' + str(total/60/60)\n",
    "super_nodes = min_vertex_sets.keys()\n",
    "super_nodes = filter(lambda x: len(min_vertex_sets[x]) > 5, super_nodes)\n",
    "print len(super_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
