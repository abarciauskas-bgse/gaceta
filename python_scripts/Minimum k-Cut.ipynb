{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum k-cut Algorithm\n",
    "\n",
    "### High-level Algorithm Specification:\n",
    "\n",
    "1. Create vertex list and an edges list, e.g.:\n",
    "\n",
    "    ```javascript\n",
    "    vertices = {1: [2,4,5], 2: [3,4,5], 3: [2,4], 4: [1,2,3], 5: [1,2]}\n",
    "    edges = [[1,2], [1,4], [1,5], [2,3], [2,4], [2,5], [3,4]]\n",
    "    ```\n",
    "\n",
    "2. Keep track of the minimum cut so far:\n",
    "\n",
    "    ```javascript\n",
    "    // really this could be the max degree of all vertices, I believe\n",
    "    min_edges_so_far = len(edges)\n",
    "    min_vertex_sets = {1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "    ```\n",
    "\n",
    "3. *Iterate at least `n^2 log n` times (where n is the original number of vertices)*\n",
    "    \n",
    "    **Intiate:**\n",
    "    \n",
    "    ```javascript\n",
    "    temp_vertex_sets = copy(min_vertex_sets)\n",
    "    temp_vertices = copy(vertices)\n",
    "    temp_edges = copy(edges)\n",
    "    ```\n",
    "\n",
    "    **While num_vertices > k:**\n",
    "\n",
    "    1. Pick an edge at random: the first vertex (`v1`) will absorb the second (`v2`). Add `v2` and `temp_vertex_sets[v2]` to `temp_vertex_sets[v1]` and delete `temp_vertex_sets[v2]`.\n",
    "    2. All vertices adjacent to `v2` are added to `temp_vertices[v1]` unless already present. Remove `v2` from `temp_vertices[v1]`.\n",
    "    3. Replace all instances of `v2` in `temp_edges` with `v1`, unless the other vertex of the edge is itself `v1`. In the latter case, delete the edge (e.g. remove self-loops). **Note:** Parallel edges are allowed; there may be multiple instances of an edge comprised the same vertex pair.\n",
    "\n",
    "    **Finally:** The number of final edges is the number of edges across the final cut in this iteration. If it is less than min_edges_so_far, update `min_edges_so_far = len(temp_edges)` and `min_vertex_sets = temp_vertex_sets`.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Select all measurements and document ids from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5070"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "database = 'fomc'\n",
    "conn = psycopg2.connect(\"dbname=\" + database + \" user=abarciauskas\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "year = 2006\n",
    "cosine_thresh = 0.2\n",
    "cur.execute(\"SELECT Doc1Id,Doc2Id,CosineSimilarity FROM alignments WHERE Year = '\" + str(year) + \"'\"\n",
    "           \" AND CosineSimilarity >= \" + str(cosine_thresh))\n",
    "cosine_sims = cur.fetchall()\n",
    "len(cosine_sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the graph\n",
    "\n",
    "The graph is comprised a list of edges (a vertex tuple) and a dictionary of vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_graph(cosine_sims, threshold):\n",
    "    similar_documents = filter(lambda x: x[2] > threshold, cosine_sims)\n",
    "    edges = [tuple([x[0],x[1]]) for x in similar_documents]\n",
    "    vertices = {}\n",
    "    for edge in edges:\n",
    "        v1 = edge[0]\n",
    "        v2 = edge[1]\n",
    "        if v1 in vertices.keys():\n",
    "            vertices[v1].add(v2)\n",
    "        else:\n",
    "            vertices[v1] = {v2}\n",
    "        if v2 in vertices.keys():\n",
    "            vertices[v2].add(v1)\n",
    "        else:\n",
    "            vertices[v2] = {v1}\n",
    "    return [edges, vertices]\n",
    "\n",
    "edges, vertices = create_graph(cosine_sims, 0.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1959"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing\n",
    "# vertices = {1: {2,4,5}, 2: {3,4,5}, 3: {2,4}, 4: {1,2,3}, 5: {1,2}}\n",
    "# edges = [{1,2}, {1,4}, {1,5}, {2,3}, {2,4}, {2,5}, {3,4}]\n",
    "print len(vertices)\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "1110\n",
      "1924\n"
     ]
    }
   ],
   "source": [
    "# need to find disconnected graphs\n",
    "graphs = []\n",
    "unvisited = set(vertices.keys())\n",
    "visited = []\n",
    "\n",
    "# for every vertex, find all of its connected components and recurse on those vertices\n",
    "current_vertex = unvisited.pop()\n",
    "visited.append(current_vertex)\n",
    "stack_to_visit = list(vertices[current_vertex])\n",
    "while len(stack_to_visit) > 0:\n",
    "    current_vertex = stack_to_visit.pop()\n",
    "    current_adj_vtcs = vertices[current_vertex]\n",
    "    for v in current_adj_vtcs:\n",
    "        if v not in visited:\n",
    "            visited.append(v)\n",
    "            unvisited.remove(v)\n",
    "            stack_to_visit.insert(0, v)\n",
    "\n",
    "graphs.append(visited)\n",
    "print len(unvisited)\n",
    "for loner in list(unvisited):\n",
    "    vertices.pop(loner, None)\n",
    "\n",
    "edges = [i for j, i in enumerate(edges) if list(i)[0] not in list(unvisited) and list(i)[1] not in list(unvisited)]\n",
    "print len(vertices.keys())\n",
    "print len(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Keep track of minimum so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_edges_so_far = len(edges)\n",
    "min_vertex_sets = {key: set() for key in vertices.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Random iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter: 0\n",
      "Total time for 1: 1.8028280735\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "def run(niters):\n",
    "    min_edges_so_far = len(edges)\n",
    "    min_vertex_sets = {key: set() for key in vertices.keys()}\n",
    "    for iteridx in range(niters):\n",
    "        if iteridx % 5 == 0: print 'Running iter: ' + str(iteridx)\n",
    "        temp_vertex_sets = {key: set() for key in vertices.keys()}\n",
    "        temp_vertices = deepcopy(vertices)\n",
    "        temp_edges = edges[:]\n",
    "        while len(temp_vertices) > k:\n",
    "            # pick an edge at random and delete it\n",
    "            rand_idx = int(random.random()*len(temp_edges))\n",
    "            random_edge = temp_edges.pop(rand_idx)\n",
    "            # Add v2 and temp_vertex_sets[v2] to temp_vertex_sets[v1] and delete temp_vertex_sets[v2]\n",
    "            v1 = list(random_edge)[0]\n",
    "            v2 = list(random_edge)[1]\n",
    "            temp_vertex_sets[v1] = temp_vertex_sets[v1].union(temp_vertex_sets[v2])\n",
    "            temp_vertex_sets[v1].add(v2)\n",
    "            temp_vertex_sets.pop(v2, None)\n",
    "\n",
    "            # All vertices adjacent to v2 are added to temp_vertices[v1] unless already present.\n",
    "            # Remove v2 from temp_vertices[v1].\n",
    "            adj_v2 = temp_vertices[v2]\n",
    "            temp_vertices[v1] = temp_vertices[v1].union(adj_v2)\n",
    "            temp_vertices[v1].remove(v2)\n",
    "            temp_vertices.pop(v2, None)\n",
    "\n",
    "            # Replace all instances of v2 in temp_edges with v1, unless the other vertex of the edge is itself v1.\n",
    "            # In the latter case, delete the edge (e.g. remove self-loops).\n",
    "            # Note: Parallel edges are allowed; there may be multiple instances of an edge comprised the same vertex pair.\n",
    "            remove_edges = []\n",
    "            for i,cur_edge in enumerate(temp_edges):\n",
    "                if len(cur_edge) > 1:\n",
    "                    cur_edge_v1 = list(cur_edge)[0]\n",
    "                    cur_edge_v2 = list(cur_edge)[1]\n",
    "                    if (cur_edge == random_edge):\n",
    "                        remove_edges.append(i)\n",
    "                    elif cur_edge_v1 == v2:\n",
    "                        temp_edges[i] = {v1, cur_edge_v2}\n",
    "                        # remove this edge from temp_vertices\n",
    "                        # it may have already been removed because we keep parallel edges around\n",
    "                        if v2 in temp_vertices[cur_edge_v2]: temp_vertices[cur_edge_v2].remove(v2)\n",
    "                    elif cur_edge_v2 == v2:\n",
    "                        temp_edges[i] = {cur_edge_v1, v1}\n",
    "                        # it may have already been removed because we keep parallel edges around\n",
    "                        if v2 in temp_vertices[cur_edge_v1]: temp_vertices[cur_edge_v1].remove(v2)\n",
    "            # work around for delete\n",
    "            temp_edges = [set(i) for j, i in enumerate(temp_edges) if j not in remove_edges]\n",
    "            #Finally: The number of final edges is the number of edges across the final cut in this iteration.\n",
    "            #If it is less than min_edges_so_far, update min_edges_so_far = len(temp_edges) and min_vertex_sets = temp_vertex_sets.\n",
    "            if len(temp_edges) < min_edges_so_far:\n",
    "                min_edges_so_far = len(temp_edges)\n",
    "                min_vertex_sets = temp_vertex_sets\n",
    "        return min_edges_so_far, min_vertex_sets\n",
    "\n",
    "k = 200\n",
    "n = len(vertices)\n",
    "niters = 1\n",
    "\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "min_edges_so_far, min_vertex_sets = run(niters)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "print 'Total time for ' + str(niters) + ': ' + str(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.7090795065\n"
     ]
    }
   ],
   "source": [
    "niters = n**2#int(np.ceil(n**2*np.log(n)))\n",
    "total_seconds = niters*total\n",
    "minutes = total_seconds/60\n",
    "hours = minutes/60\n",
    "print hours/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1232100\n",
      "Running iter: 0\n",
      "Total time for 1232100: 0.000500785575973 hours\n"
     ]
    }
   ],
   "source": [
    "print niters\n",
    "t0 = time.time()\n",
    "min_edges_so_far, min_vertex_sets = run(niters)\n",
    "t1 = time.time()\n",
    "print 'Total time for ' + str(niters) + ': ' + str(total/60/60) + ' hours'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
